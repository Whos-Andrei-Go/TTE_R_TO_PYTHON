{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfamilies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m family\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfamilies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m links\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.families import family\n",
    "from statsmodels.genmod.families import links\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from IPython.display import display\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "\n",
    "# Function to generate data for target trial emulation\n",
    "def generate_synthetic_data(n_patients=10000):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for target trial emulation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_patients : int\n",
    "        Number of patients to simulate\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame containing simulated patient data\n",
    "    \"\"\"\n",
    "    # Generate baseline covariates\n",
    "    age = np.random.normal(65, 10, n_patients)  # Age centered around 65\n",
    "    male = np.random.binomial(1, 0.5, n_patients)  # Gender\n",
    "    bmi = np.random.normal(27, 5, n_patients)  # BMI\n",
    "    diabetes = np.random.binomial(1, 0.3, n_patients)  # Diabetes status\n",
    "    hypertension = np.random.binomial(1, 0.4, n_patients)  # Hypertension status\n",
    "    smoking = np.random.binomial(1, 0.25, n_patients)  # Smoking status\n",
    "    \n",
    "    # Generate treatment assignment based on covariates\n",
    "    # Higher probability of treatment for older, male patients with comorbidities\n",
    "    logit_treat = -2 + 0.02*age + 0.5*male + 0.03*bmi + 0.7*diabetes + 0.6*hypertension + 0.4*smoking\n",
    "    p_treat = 1 / (1 + np.exp(-logit_treat))\n",
    "    treatment = np.random.binomial(1, p_treat, n_patients)\n",
    "    \n",
    "    # Generate outcome based on treatment and covariates\n",
    "    # Treatment has a protective effect (negative coefficient)\n",
    "    logit_outcome = -3 + 0.03*age + 0.3*male + 0.02*bmi + 0.6*diabetes + 0.5*hypertension + 0.3*smoking - 0.7*treatment\n",
    "    p_outcome = 1 / (1 + np.exp(-logit_outcome))\n",
    "    outcome = np.random.binomial(1, p_outcome, n_patients)\n",
    "    \n",
    "    # Generate time-to-event data\n",
    "    # Higher hazard for older patients with comorbidities, lower hazard for treated\n",
    "    lambda_event = np.exp(-5 + 0.02*age + 0.3*male + 0.01*bmi + 0.5*diabetes + 0.4*hypertension + 0.2*smoking - 0.6*treatment)\n",
    "    time_to_event = np.random.exponential(1/lambda_event)\n",
    "    \n",
    "    # Generate censoring times\n",
    "    censoring_time = np.random.exponential(1/0.1, n_patients)\n",
    "    \n",
    "    # Take minimum of event time and censoring time\n",
    "    observed_time = np.minimum(time_to_event, censoring_time)\n",
    "    event = (time_to_event <= censoring_time).astype(int)\n",
    "    \n",
    "    # Create dataframe\n",
    "    data = pd.DataFrame({\n",
    "        'patient_id': range(1, n_patients + 1),\n",
    "        'age': age,\n",
    "        'male': male,\n",
    "        'bmi': bmi,\n",
    "        'diabetes': diabetes,\n",
    "        'hypertension': hypertension,\n",
    "        'smoking': smoking,\n",
    "        'treatment': treatment,\n",
    "        'outcome': outcome,\n",
    "        'time': observed_time,\n",
    "        'event': event\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate the data\n",
    "data = generate_synthetic_data(10000)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(\"Sample of synthetic patient data:\")\n",
    "display(data.head())\n",
    "\n",
    "# Descriptive statistics by treatment group\n",
    "def descriptive_stats_by_treatment(data):\n",
    "    \"\"\"Generate descriptive statistics by treatment group\"\"\"\n",
    "    stats_dict = {}\n",
    "    \n",
    "    for var in ['age', 'male', 'bmi', 'diabetes', 'hypertension', 'smoking', 'outcome', 'time', 'event']:\n",
    "        # Calculate statistics for treated group\n",
    "        treated_stats = data[data.treatment == 1][var].describe()\n",
    "        \n",
    "        # Calculate statistics for untreated group\n",
    "        untreated_stats = data[data.treatment == 0][var].describe()\n",
    "        \n",
    "        # For binary variables, calculate percentages\n",
    "        if var in ['male', 'diabetes', 'hypertension', 'smoking', 'outcome', 'event']:\n",
    "            treated_pct = data[data.treatment == 1][var].mean() * 100\n",
    "            untreated_pct = data[data.treatment == 0][var].mean() * 100\n",
    "            \n",
    "            # Calculate p-value using chi-square test\n",
    "            contingency_table = pd.crosstab(data['treatment'], data[var])\n",
    "            chi2, p_value = stats.chi2_contingency(contingency_table)[:2]\n",
    "            \n",
    "            stats_dict[var] = {\n",
    "                'Treated': f\"{treated_pct:.1f}%\",\n",
    "                'Untreated': f\"{untreated_pct:.1f}%\",\n",
    "                'p-value': f\"{p_value:.4f}\"\n",
    "            }\n",
    "        else:\n",
    "            # Calculate p-value using t-test\n",
    "            t_stat, p_value = stats.ttest_ind(\n",
    "                data[data.treatment == 1][var].dropna(),\n",
    "                data[data.treatment == 0][var].dropna()\n",
    "            )\n",
    "            \n",
    "            stats_dict[var] = {\n",
    "                'Treated': f\"{treated_stats['mean']:.2f} ± {treated_stats['std']:.2f}\",\n",
    "                'Untreated': f\"{untreated_stats['mean']:.2f} ± {untreated_stats['std']:.2f}\",\n",
    "                'p-value': f\"{p_value:.4f}\"\n",
    "            }\n",
    "            \n",
    "    return pd.DataFrame(stats_dict).T\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "desc_stats = descriptive_stats_by_treatment(data)\n",
    "print(\"\\nDescriptive statistics by treatment group:\")\n",
    "display(desc_stats)\n",
    "\n",
    "# Calculate propensity scores\n",
    "def calculate_propensity_scores(data, covariates):\n",
    "    \"\"\"\n",
    "    Calculate propensity scores using logistic regression\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Patient data\n",
    "    covariates : list\n",
    "        List of covariate column names\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Series containing propensity scores\n",
    "    \"\"\"\n",
    "    X = data[covariates]\n",
    "    y = data['treatment']\n",
    "    \n",
    "    # Fit logistic regression model\n",
    "    logistic_model = LogisticRegression(max_iter=1000)\n",
    "    logistic_model.fit(X, y)\n",
    "    \n",
    "    # Calculate propensity scores\n",
    "    propensity_scores = logistic_model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    return propensity_scores\n",
    "\n",
    "# Calculate propensity scores\n",
    "covariates = ['age', 'male', 'bmi', 'diabetes', 'hypertension', 'smoking']\n",
    "data['propensity_score'] = calculate_propensity_scores(data, covariates)\n",
    "\n",
    "# Visualize propensity score distributions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=data, x='propensity_score', hue='treatment', bins=30, element='step', common_norm=False)\n",
    "plt.title('Propensity Score Distribution by Treatment Group')\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Perform inverse probability weighting (IPW)\n",
    "def inverse_probability_weighting(data):\n",
    "    \"\"\"\n",
    "    Perform inverse probability of treatment weighting (IPTW)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Patient data with propensity scores\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with added IPW weights\n",
    "    \"\"\"\n",
    "    # Create a copy of the data\n",
    "    weighted_data = data.copy()\n",
    "    \n",
    "    # Calculate weights\n",
    "    weighted_data['ipw'] = np.where(\n",
    "        weighted_data['treatment'] == 1,\n",
    "        1 / weighted_data['propensity_score'],\n",
    "        1 / (1 - weighted_data['propensity_score'])\n",
    "    )\n",
    "    \n",
    "    # Stabilize weights\n",
    "    treated_prob = weighted_data['treatment'].mean()\n",
    "    weighted_data['ipw_stabilized'] = np.where(\n",
    "        weighted_data['treatment'] == 1,\n",
    "        treated_prob / weighted_data['propensity_score'],\n",
    "        (1 - treated_prob) / (1 - weighted_data['propensity_score'])\n",
    "    )\n",
    "    \n",
    "    return weighted_data\n",
    "\n",
    "# Apply IPW\n",
    "weighted_data = inverse_probability_weighting(data)\n",
    "\n",
    "# Check balance after weighting\n",
    "def check_covariate_balance(data, weighted_data, covariates):\n",
    "    \"\"\"\n",
    "    Check covariate balance before and after weighting\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Original patient data\n",
    "    weighted_data : DataFrame\n",
    "        Weighted patient data\n",
    "    covariates : list\n",
    "        List of covariate column names\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with standardized mean differences\n",
    "    \"\"\"\n",
    "    balance_results = []\n",
    "    \n",
    "    for var in covariates:\n",
    "        # Unweighted standardized difference\n",
    "        treated_mean = data[data.treatment == 1][var].mean()\n",
    "        treated_var = data[data.treatment == 1][var].var()\n",
    "        \n",
    "        untreated_mean = data[data.treatment == 0][var].mean()\n",
    "        untreated_var = data[data.treatment == 0][var].var()\n",
    "        \n",
    "        pooled_sd = np.sqrt((treated_var + untreated_var) / 2)\n",
    "        unweighted_smd = abs(treated_mean - untreated_mean) / pooled_sd if pooled_sd > 0 else 0\n",
    "        \n",
    "        # Weighted standardized difference\n",
    "        treated_weight_sum = weighted_data[weighted_data.treatment == 1]['ipw_stabilized'].sum()\n",
    "        untreated_weight_sum = weighted_data[weighted_data.treatment == 0]['ipw_stabilized'].sum()\n",
    "        \n",
    "        weighted_treated_mean = (weighted_data[weighted_data.treatment == 1][var] * \n",
    "                                weighted_data[weighted_data.treatment == 1]['ipw_stabilized']).sum() / treated_weight_sum\n",
    "        \n",
    "        weighted_untreated_mean = (weighted_data[weighted_data.treatment == 0][var] * \n",
    "                                  weighted_data[weighted_data.treatment == 0]['ipw_stabilized']).sum() / untreated_weight_sum\n",
    "        \n",
    "        weighted_smd = abs(weighted_treated_mean - weighted_untreated_mean) / pooled_sd if pooled_sd > 0 else 0\n",
    "        \n",
    "        balance_results.append({\n",
    "            'Variable': var,\n",
    "            'Unweighted_SMD': unweighted_smd,\n",
    "            'Weighted_SMD': weighted_smd\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(balance_results)\n",
    "\n",
    "# Check balance\n",
    "balance_df = check_covariate_balance(data, weighted_data, covariates)\n",
    "print(\"\\nCovariate balance before and after weighting:\")\n",
    "display(balance_df)\n",
    "\n",
    "# Plot balance\n",
    "plt.figure(figsize=(10, 6))\n",
    "balance_plot = pd.melt(balance_df, id_vars=['Variable'], \n",
    "                       value_vars=['Unweighted_SMD', 'Weighted_SMD'],\n",
    "                       var_name='Method', value_name='Standardized Mean Difference')\n",
    "\n",
    "sns.barplot(data=balance_plot, x='Variable', y='Standardized Mean Difference', hue='Method')\n",
    "plt.axhline(y=0.1, color='r', linestyle='--', label='Threshold (0.1)')\n",
    "plt.title('Covariate Balance Before and After Weighting')\n",
    "plt.legend(title='')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estimate treatment effect using weighted regression\n",
    "def estimate_treatment_effect(weighted_data, covariates):\n",
    "    \"\"\"\n",
    "    Estimate treatment effect using weighted regression\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weighted_data : DataFrame\n",
    "        Weighted patient data\n",
    "    covariates : list\n",
    "        List of covariate column names\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Fitted model and summary\n",
    "    \"\"\"\n",
    "    # Prepare data for regression\n",
    "    X = weighted_data[['treatment'] + covariates].copy()\n",
    "    X = sm.add_constant(X)\n",
    "    y = weighted_data['outcome']\n",
    "    weights = weighted_data['ipw_stabilized']\n",
    "    \n",
    "    # Fit weighted logistic regression\n",
    "    model = sm.GLM(y, X, family=family.Binomial(link=links.logit()), freq_weights=weights)\n",
    "    result = model.fit()\n",
    "    \n",
    "    # Convert log odds to odds ratios\n",
    "    params = result.params.copy()\n",
    "    conf_int = result.conf_int()\n",
    "    \n",
    "    odds_ratios = np.exp(params)\n",
    "    odds_ratios_ci = np.exp(conf_int)\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Odds Ratio': odds_ratios,\n",
    "        'Lower 95% CI': odds_ratios_ci[0],\n",
    "        'Upper 95% CI': odds_ratios_ci[1],\n",
    "        'p-value': result.pvalues\n",
    "    })\n",
    "    \n",
    "    return result, summary_df\n",
    "\n",
    "# Estimate treatment effect\n",
    "model, effect_summary = estimate_treatment_effect(weighted_data, covariates)\n",
    "print(\"\\nTreatment effect estimation:\")\n",
    "display(effect_summary)\n",
    "\n",
    "# Time-to-event analysis\n",
    "def time_to_event_analysis(weighted_data):\n",
    "    \"\"\"\n",
    "    Perform time-to-event analysis using weighted Cox regression\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weighted_data : DataFrame\n",
    "        Weighted patient data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Estimated hazard ratio for treatment effect\n",
    "    \"\"\"\n",
    "    # Note: For a full implementation, you would use lifelines or other survival analysis package\n",
    "    # Since we're just providing a conceptual Python equivalent, we'll simplify this part\n",
    "    \n",
    "    # The following is a placeholder to represent the general approach\n",
    "    print(\"\\nTime-to-event analysis:\")\n",
    "    print(\"Note: In a complete implementation, you would use the lifelines package\")\n",
    "    print(\"to perform a weighted Cox proportional hazards regression.\")\n",
    "    print(\"\\nExample code:\")\n",
    "    print(\"from lifelines import CoxPHFitter\")\n",
    "    print(\"cox_model = CoxPHFitter()\")\n",
    "    print(\"cox_model.fit(weighted_data, duration_col='time', event_col='event', weights_col='ipw_stabilized')\")\n",
    "    print(\"cox_model.print_summary()\")\n",
    "    \n",
    "    # For simplicity, report the ratio of event rates as crude approximation\n",
    "    treated_events = weighted_data[weighted_data.treatment == 1]['event'].sum()\n",
    "    treated_time = weighted_data[weighted_data.treatment == 1]['time'].sum()\n",
    "    treated_rate = treated_events / treated_time\n",
    "    \n",
    "    untreated_events = weighted_data[weighted_data.treatment == 0]['event'].sum()\n",
    "    untreated_time = weighted_data[weighted_data.treatment == 0]['time'].sum()\n",
    "    untreated_rate = untreated_events / untreated_time\n",
    "    \n",
    "    crude_hr = treated_rate / untreated_rate\n",
    "    \n",
    "    return {\n",
    "        'Crude Hazard Ratio': crude_hr,\n",
    "        'Treated Event Rate': treated_rate,\n",
    "        'Untreated Event Rate': untreated_rate\n",
    "    }\n",
    "\n",
    "# Perform time-to-event analysis\n",
    "survival_results = time_to_event_analysis(weighted_data)\n",
    "print(\"\\nApproximate time-to-event results:\")\n",
    "for key, value in survival_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# Sensitivity analysis\n",
    "def sensitivity_analysis(data, covariates, trim_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Perform sensitivity analysis by trimming extreme propensity scores\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Patient data\n",
    "    covariates : list\n",
    "        List of covariate column names\n",
    "    trim_threshold : float\n",
    "        Threshold for trimming propensity scores\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with trimmed data and weights\n",
    "    \"\"\"\n",
    "    # Create trimmed dataset\n",
    "    trimmed_data = data[(data['propensity_score'] >= trim_threshold) & \n",
    "                        (data['propensity_score'] <= (1 - trim_threshold))].copy()\n",
    "    \n",
    "    print(f\"\\nTrimmed {len(data) - len(trimmed_data)} patients with extreme propensity scores\")\n",
    "    print(f\"Remaining sample size: {len(trimmed_data)}\")\n",
    "    \n",
    "    # Recalculate weights\n",
    "    trimmed_data['ipw'] = np.where(\n",
    "        trimmed_data['treatment'] == 1,\n",
    "        1 / trimmed_data['propensity_score'],\n",
    "        1 / (1 - trimmed_data['propensity_score'])\n",
    "    )\n",
    "    \n",
    "    treated_prob = trimmed_data['treatment'].mean()\n",
    "    trimmed_data['ipw_stabilized'] = np.where(\n",
    "        trimmed_data['treatment'] == 1,\n",
    "        treated_prob / trimmed_data['propensity_score'],\n",
    "        (1 - treated_prob) / (1 - trimmed_data['propensity_score'])\n",
    "    )\n",
    "    \n",
    "    return trimmed_data\n",
    "\n",
    "# Perform sensitivity analysis\n",
    "trimmed_data = sensitivity_analysis(data, covariates, trim_threshold=0.05)\n",
    "\n",
    "# Re-estimate treatment effect with trimmed data\n",
    "trimmed_model, trimmed_effect = estimate_treatment_effect(trimmed_data, covariates)\n",
    "print(\"\\nTreatment effect estimation after trimming:\")\n",
    "display(trimmed_effect)\n",
    "\n",
    "# Subgroup analysis\n",
    "def subgroup_analysis(weighted_data, subgroup_var):\n",
    "    \"\"\"\n",
    "    Perform subgroup analysis for treatment effect\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weighted_data : DataFrame\n",
    "        Weighted patient data\n",
    "    subgroup_var : str\n",
    "        Variable name to define subgroups\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dictionary with subgroup treatment effects\n",
    "    \"\"\"\n",
    "    subgroup_results = {}\n",
    "    \n",
    "    for subgroup_value in weighted_data[subgroup_var].unique():\n",
    "        subgroup_data = weighted_data[weighted_data[subgroup_var] == subgroup_value]\n",
    "        \n",
    "        # Simple calculation of risk difference\n",
    "        treated = subgroup_data[subgroup_data.treatment == 1]\n",
    "        untreated = subgroup_data[subgroup_data.treatment == 0]\n",
    "        \n",
    "        treated_risk = (treated['outcome'] * treated['ipw_stabilized']).sum() / treated['ipw_stabilized'].sum()\n",
    "        untreated_risk = (untreated['outcome'] * untreated['ipw_stabilized']).sum() / untreated['ipw_stabilized'].sum()\n",
    "        \n",
    "        risk_difference = treated_risk - untreated_risk\n",
    "        \n",
    "        subgroup_results[f\"{subgroup_var}={subgroup_value}\"] = {\n",
    "            'Treated Risk': treated_risk,\n",
    "            'Untreated Risk': untreated_risk,\n",
    "            'Risk Difference': risk_difference,\n",
    "            'Sample Size': len(subgroup_data)\n",
    "        }\n",
    "    \n",
    "    return subgroup_results\n",
    "\n",
    "# Perform subgroup analysis for diabetes\n",
    "diabetes_subgroups = subgroup_analysis(weighted_data, 'diabetes')\n",
    "print(\"\\nSubgroup analysis by diabetes status:\")\n",
    "for subgroup, results in diabetes_subgroups.items():\n",
    "    print(f\"\\n{subgroup}:\")\n",
    "    for key, value in results.items():\n",
    "        print(f\"  {key}: {value:.4f}\" if isinstance(value, float) else f\"  {key}: {value}\")\n",
    "\n",
    "# Perform matching as alternative to weighting\n",
    "def perform_matching(data, covariates, caliper=0.2):\n",
    "    \"\"\"\n",
    "    Perform propensity score matching\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Patient data\n",
    "    covariates : list\n",
    "        List of covariate column names\n",
    "    caliper : float\n",
    "        Caliper width for matching\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with matched pairs\n",
    "    \"\"\"\n",
    "    # Create a copy of the data\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Initialize empty dataframe for matched pairs\n",
    "    matched_pairs = pd.DataFrame()\n",
    "    \n",
    "    # Get treated and untreated patients\n",
    "    treated = df[df.treatment == 1].copy().reset_index(drop=True)\n",
    "    untreated = df[df.treatment == 0].copy().reset_index(drop=True)\n",
    "    \n",
    "    # Calculate propensity score SD for caliper\n",
    "    ps_sd = df['propensity_score'].std()\n",
    "    caliper_width = caliper * ps_sd\n",
    "    \n",
    "    # Create arrays to keep track of matched status\n",
    "    treated_matched = np.zeros(len(treated), dtype=bool)\n",
    "    untreated_matched = np.zeros(len(untreated), dtype=bool)\n",
    "    \n",
    "    # For each treated patient, find the best match\n",
    "    for i in range(len(treated)):\n",
    "        if treated_matched[i]:\n",
    "            continue\n",
    "            \n",
    "        treated_ps = treated.loc[i, 'propensity_score']\n",
    "        \n",
    "        # Calculate absolute differences in propensity scores\n",
    "        diffs = np.abs(untreated['propensity_score'] - treated_ps)\n",
    "        \n",
    "        # Find eligible matches (within caliper and not already matched)\n",
    "        eligible = (~untreated_matched) & (diffs <= caliper_width)\n",
    "        \n",
    "        if np.any(eligible):\n",
    "            # Find the best match\n",
    "            best_match_idx = diffs[eligible].idxmin()\n",
    "            \n",
    "            # Mark as matched\n",
    "            treated_matched[i] = True\n",
    "            untreated_matched[best_match_idx] = True\n",
    "            \n",
    "            # Add pair to result\n",
    "            pair = pd.concat([treated.loc[[i]], untreated.loc[[best_match_idx]]])\n",
    "            matched_pairs = pd.concat([matched_pairs, pair])\n",
    "    \n",
    "    print(f\"\\nMatching results:\")\n",
    "    print(f\"Treated patients matched: {treated_matched.sum()} out of {len(treated)}\")\n",
    "    print(f\"Matching rate: {treated_matched.sum()/len(treated):.2%}\")\n",
    "    \n",
    "    return matched_pairs\n",
    "\n",
    "# Perform matching\n",
    "matched_data = perform_matching(data, covariates)\n",
    "\n",
    "# Analyze matched data\n",
    "def analyze_matched_data(matched_data):\n",
    "    \"\"\"\n",
    "    Analyze treatment effect in matched data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    matched_data : DataFrame\n",
    "        Matched patient data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Treatment effect estimate\n",
    "    \"\"\"\n",
    "    # Simple difference in outcome rates\n",
    "    treated = matched_data[matched_data.treatment == 1]\n",
    "    untreated = matched_data[matched_data.treatment == 0]\n",
    "    \n",
    "    treated_outcome_rate = treated['outcome'].mean()\n",
    "    untreated_outcome_rate = untreated['outcome'].mean()\n",
    "    \n",
    "    risk_difference = treated_outcome_rate - untreated_outcome_rate\n",
    "    odds_ratio = (treated_outcome_rate / (1 - treated_outcome_rate)) / (untreated_outcome_rate / (1 - untreated_outcome_rate))\n",
    "    \n",
    "    return {\n",
    "        'Treated Outcome Rate': treated_outcome_rate,\n",
    "        'Untreated Outcome Rate': untreated_outcome_rate,\n",
    "        'Risk Difference': risk_difference,\n",
    "        'Odds Ratio': odds_ratio\n",
    "    }\n",
    "\n",
    "# Analyze matched data if we have any matches\n",
    "if len(matched_data) > 0:\n",
    "    matched_results = analyze_matched_data(matched_data)\n",
    "    print(\"\\nTreatment effect in matched data:\")\n",
    "    for key, value in matched_results.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# Create a function to summarize results\n",
    "def summarize_results(data, weighted_data, effect_summary, subgroup_results, survival_results):\n",
    "    \"\"\"Summarize all results of the target trial emulation\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TARGET TRIAL EMULATION SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Dataset information\n",
    "    print(f\"\\nDataset: {len(data)} patients\")\n",
    "    print(f\"Treatment group: {data['treatment'].sum()} patients ({data['treatment'].mean()*100:.1f}%)\")\n",
    "    print(f\"Control group: {len(data) - data['treatment'].sum()} patients ({(1-data['treatment'].mean())*100:.1f}%)\")\n",
    "    \n",
    "    # Primary outcome\n",
    "    print(f\"\\nPrimary outcome event rate: {data['outcome'].mean()*100:.1f}%\")\n",
    "    \n",
    "    # Main treatment effect\n",
    "    treatment_or = effect_summary.loc['treatment', 'Odds Ratio']\n",
    "    treatment_ci_lower = effect_summary.loc['treatment', 'Lower 95% CI']\n",
    "    treatment_ci_upper = effect_summary.loc['treatment', 'Upper 95% CI']\n",
    "    treatment_p = effect_summary.loc['treatment', 'p-value']\n",
    "    \n",
    "    print(f\"\\nPrimary analysis - Treatment effect:\")\n",
    "    print(f\"Odds Ratio: {treatment_or:.2f} (95% CI: {treatment_ci_lower:.2f} - {treatment_ci_upper:.2f}), p = {treatment_p:.4f}\")\n",
    "    \n",
    "    # Interpretation based on direction of effect\n",
    "    if treatment_or < 1 and treatment_p < 0.05:\n",
    "        print(\"Interpretation: Treatment significantly reduces the odds of the outcome\")\n",
    "    elif treatment_or > 1 and treatment_p < 0.05:\n",
    "        print(\"Interpretation: Treatment significantly increases the odds of the outcome\")\n",
    "    else:\n",
    "        print(\"Interpretation: No statistically significant effect of treatment detected\")\n",
    "    \n",
    "    # Survival analysis\n",
    "    if survival_results:\n",
    "        print(f\"\\nTime-to-event analysis - Crude Hazard Ratio: {survival_results['Crude Hazard Ratio']:.2f}\")\n",
    "    \n",
    "    # Subgroup analysis\n",
    "    if subgroup_results:\n",
    "        print(\"\\nSubgroup analysis:\")\n",
    "        for subgroup, results in subgroup_results.items():\n",
    "            print(f\"  {subgroup}: Risk Difference = {results['Risk Difference']:.4f}\")\n",
    "\n",
    "# Summarize all results\n",
    "summarize_results(data, weighted_data, effect_summary, diabetes_subgroups, survival_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
